{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8BwWBefSbgr",
        "outputId": "73b512e7-44e8-4936-e3ee-87496abcf750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'itmo-kaggle-inclass'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 21 (delta 10), reused 5 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (21/21), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/23lnlx/itmo-kaggle-inclass.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPna6oAjWPcr"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7mYwXDIXR1H",
        "outputId": "84ea5d2c-f00e-4591-fe8d-4db408e7b7dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading itmo-acoustic-event-detection-2022.zip to /content\n",
            "100% 7.31G/7.34G [01:06<00:00, 110MB/s]\n",
            "100% 7.34G/7.34G [01:06<00:00, 119MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c itmo-acoustic-event-detection-2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-SxKTvEYlgL"
      },
      "outputs": [],
      "source": [
        "! mkdir kdata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxMNXuDTYzd8"
      },
      "outputs": [],
      "source": [
        "! unzip itmo-acoustic-event-detection-2022.zip -d kdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zu0AhkyTaBQI"
      },
      "outputs": [],
      "source": [
        "! pip install efficientnet-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorchtools"
      ],
      "metadata": {
        "id": "tm5rveXrXZuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlFXzCCrSRon"
      },
      "outputs": [],
      "source": [
        "# path to your train/test/meta folders\n",
        "DATA_PATH = '/content/kdata/'\n",
        "\n",
        "# names of valuable files/folders\n",
        "train_meta_fname = 'train.csv'\n",
        "test_meta_fname = 'sample_submission.csv'\n",
        "train_data_folder = 'audio_train/train'\n",
        "test_data_folder = 'audio_test/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tg6RpNCUcfDe"
      },
      "outputs": [],
      "source": [
        "! pip install torchaudio torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWx9rXG4SRor"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchaudio\n",
        "import torchvision\n",
        "from torchaudio import transforms\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from torch.optim.lr_scheduler import CyclicLR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQLpbv5ESRos"
      },
      "outputs": [],
      "source": [
        "# set seeds\n",
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "jT5c8-xcSRos",
        "outputId": "33fdaf01-16bc-4521-93a2-0432926513e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      fname            label\n",
              "0  8bcbcc394ba64fe85ed4.wav  Finger_snapping\n",
              "1  00d77b917e241afa06f1.wav           Squeak"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-698c2639-f035-490f-9b66-f02f6db86a8f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8bcbcc394ba64fe85ed4.wav</td>\n",
              "      <td>Finger_snapping</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00d77b917e241afa06f1.wav</td>\n",
              "      <td>Squeak</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-698c2639-f035-490f-9b66-f02f6db86a8f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-698c2639-f035-490f-9b66-f02f6db86a8f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-698c2639-f035-490f-9b66-f02f6db86a8f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "df_train = pd.read_csv(os.path.join(DATA_PATH, train_meta_fname))\n",
        "df_test = pd.read_csv(os.path.join(DATA_PATH, test_meta_fname))\n",
        "df_train.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "6BxJ0e_7SRot",
        "outputId": "eaf6a909-3b2b-4846-b69a-ac415c66c458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      fname            label  label_encoded\n",
              "0  8bcbcc394ba64fe85ed4.wav  Finger_snapping              0\n",
              "1  00d77b917e241afa06f1.wav           Squeak              1\n",
              "2  17bb93b73b8e79234cb3.wav   Electric_piano              2\n",
              "3  7d5c7a40a936136da55e.wav        Harmonica              3\n",
              "4  17e0ee7565a33d6c2326.wav       Snare_drum              4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cab48db2-79f6-4aa5-8c1b-43d0fe720d1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fname</th>\n",
              "      <th>label</th>\n",
              "      <th>label_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8bcbcc394ba64fe85ed4.wav</td>\n",
              "      <td>Finger_snapping</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00d77b917e241afa06f1.wav</td>\n",
              "      <td>Squeak</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17bb93b73b8e79234cb3.wav</td>\n",
              "      <td>Electric_piano</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7d5c7a40a936136da55e.wav</td>\n",
              "      <td>Harmonica</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17e0ee7565a33d6c2326.wav</td>\n",
              "      <td>Snare_drum</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cab48db2-79f6-4aa5-8c1b-43d0fe720d1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cab48db2-79f6-4aa5-8c1b-43d0fe720d1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cab48db2-79f6-4aa5-8c1b-43d0fe720d1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "n_classes = df_train.label.nunique()\n",
        "print(n_classes)\n",
        "classes_dict = {cl:i for i,cl in enumerate(df_train.label.unique())}\n",
        "df_train['label_encoded'] = df_train.label.map(classes_dict)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7proBDeMSRou"
      },
      "outputs": [],
      "source": [
        "# https://github.com/lukemelas/EfficientNet-PyTorch\n",
        "class BaseLineModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, sample_rate=16000, n_classes=41):\n",
        "        super().__init__()\n",
        "        # self.ms = torchaudio.transforms.MelSpectrogram(sample_rate)\n",
        "#         self.bn1 = nn.BatchNorm2d(1)\n",
        "        \n",
        "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=3, padding=1)\n",
        "        self.cnn3 = nn.Conv2d(in_channels=10, out_channels=3, kernel_size=3, padding=1)\n",
        "        \n",
        "        self.features = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "        # use it as features\n",
        "#         for param in self.features.parameters():\n",
        "#             param.requires_grad = False\n",
        "            \n",
        "        self.lin1 = nn.Linear(1000, 333)\n",
        "        \n",
        "        self.lin2 = nn.Linear(333, 111)\n",
        "                \n",
        "        self.lin3 = nn.Linear(111, n_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x = self.ms(x)\n",
        "#         x = self.bn1(x)\n",
        "                \n",
        "        x = F.relu(self.cnn1(x))\n",
        "        x = F.relu(self.cnn3(x))\n",
        "        \n",
        "        x = self.features(x)\n",
        "\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = self.lin3(x)\n",
        "        return x\n",
        "    \n",
        "    def inference(self, x):\n",
        "        x = self.forward(x)\n",
        "        x = F.softmax(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROAgMuEmSRov"
      },
      "outputs": [],
      "source": [
        "def sample_or_pad(waveform, wav_len=32000):\n",
        "    m, n = waveform.shape\n",
        "    if n < wav_len:\n",
        "        padded_wav = torch.zeros(1, wav_len)\n",
        "        padded_wav[:, :n] = waveform\n",
        "        return padded_wav\n",
        "    elif n > wav_len:\n",
        "        offset = np.random.randint(0, n - wav_len)\n",
        "        sampled_wav = waveform[:, offset:offset+wav_len]\n",
        "        return sampled_wav\n",
        "    else:\n",
        "        return waveform\n",
        "\n",
        "# class EventDetectionDataset(Dataset):\n",
        "#     def __init__(self, data_path, x, y=None):\n",
        "#         self.x = x\n",
        "#         self.y = y\n",
        "#         self.data_path = data_path\n",
        "#         self.mel_spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=16000)\n",
        "    \n",
        "#     def __len__(self):\n",
        "#         return len(self.x)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         path2wav = os.path.join(self.data_path, self.x[idx])\n",
        "#         waveform, sample_rate = torchaudio.load(path2wav, normalize=True)\n",
        "#         waveform = sample_or_pad(waveform)\n",
        "#         spec = self.mel_spectrogram(waveform)\n",
        "#         label = torch.zeros(41)\n",
        "#         label[self.y[idx]] = 1.\n",
        "#         if self.y is not None:\n",
        "#             # return waveform, self.y[idx]\n",
        "#             if self.train and idx > 0 and idx%5 == 0:\n",
        "\n",
        "# #             # Choose another image/label randomly\n",
        "#             mixup_idx = random.randint(0, len(self.x)-1)\n",
        "#             path2wav = os.path.join(self.data_path, self.x[mixup_idx])\n",
        "#             mixup_waveform, sample_rate = torchaudio.load(path2wav, normalize=True)\n",
        "#             mixup_waveform = sample_or_pad(mixup_waveform)\n",
        "#             return spec, label\n",
        "#         return waveform\n",
        "        \n",
        "class EventDetectionDataset(Dataset):\n",
        "    def __init__(self, data_path, x, y=None, sr=16000, train=False):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.data_path = data_path\n",
        "        self.train = train\n",
        "        self.mel_spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=sr)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path2wav = os.path.join(self.data_path, self.x[idx])\n",
        "        waveform, sample_rate = torchaudio.load(path2wav, normalize=True)\n",
        "        waveform = sample_or_pad(waveform)\n",
        "        \n",
        "        spec = self.mel_spectrogram(waveform)\n",
        "        # print(type(spec), type(label))\n",
        "        if self.y is not None:\n",
        "          label = torch.zeros(41)\n",
        "          label[self.y[idx]] = 1.\n",
        "          # print(idx)\n",
        "          if self.train and idx > 0 and idx%5 == 0:\n",
        "\n",
        "            # Choose another image/label randomly\n",
        "            mixup_idx = random.randint(0, len(self.x)-1)\n",
        "            path2wav = os.path.join(self.data_path, self.x[mixup_idx])\n",
        "            mixup_waveform, sample_rate = torchaudio.load(path2wav, normalize=True)\n",
        "            mixup_waveform = sample_or_pad(mixup_waveform)\n",
        "\n",
        "            mixup_label = torch.zeros(41)\n",
        "            mixup_label[self.y[mixup_idx]] = 1.\n",
        "            mixup_spec = self.mel_spectrogram(mixup_waveform)\n",
        "            # if self.transform:\n",
        "                # mixup_image = transform(self.x[mixup_idx])\n",
        "\n",
        "            # Select a random number from the given beta distribution\n",
        "            # Mixup the images accordingly\n",
        "            alpha = 0.2\n",
        "            lam = np.random.beta(alpha, alpha)\n",
        "            spec = lam * spec + (1 - lam) * mixup_spec\n",
        "            label = lam * label + (1 - lam) * mixup_label\n",
        "            # print(type(spec), type(label))\n",
        "          return spec, label\n",
        "        return spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wVjWuptSRov"
      },
      "outputs": [],
      "source": [
        "sr = 16000\n",
        "X_train, X_val, y_train, y_val = train_test_split(df_train.fname.values, df_train.label_encoded.values, \n",
        "                                                  test_size=0.2, random_state=42)\n",
        "train_loader = DataLoader(\n",
        "                        EventDetectionDataset(os.path.join(DATA_PATH, train_data_folder), X_train, y_train, train=True),\n",
        "                        batch_size=41\n",
        "                )\n",
        "val_loader = DataLoader(\n",
        "                        EventDetectionDataset(os.path.join(DATA_PATH, train_data_folder), X_val, y_val),\n",
        "                        batch_size=41\n",
        "                )\n",
        "test_loader = DataLoader(\n",
        "                        EventDetectionDataset(os.path.join(DATA_PATH, test_data_folder), df_test.fname.values, None),\n",
        "                        batch_size=41, shuffle=False\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYV6QqaJSRow"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, eval_dataset):\n",
        "    model.eval()\n",
        "    forecast, true_labs = [], []\n",
        "    with torch.no_grad():\n",
        "        for wavs, labs in eval_dataset:\n",
        "            wavs, labs = wavs.cuda(), labs.detach().numpy().argmax(axis=1)\n",
        "            true_labs.append(labs)\n",
        "            outputs = model.inference(wavs)\n",
        "            \n",
        "            outputs = outputs.detach().cpu().numpy().argmax(axis=1)\n",
        "            forecast.append(outputs)\n",
        "    forecast = [x for sublist in forecast for x in sublist]\n",
        "    true_labs = [x for sublist in true_labs for x in sublist]\n",
        "    return f1_score(forecast, true_labs, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kjVDXQvSRow",
        "outputId": "9a8d5d79-8660-4c2d-dd3d-81f6eba1af25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "model = BaseLineModel()\n",
        "model = model.cuda()\n",
        "lr = 1e-3\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epoch = 100\n",
        "best_f1 = 0\n",
        "for epoch in range(n_epoch):\n",
        "    model.train()\n",
        "    for wavs, labs in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        wavs, labs = wavs.cuda(), labs.cuda()\n",
        "        outputs = model(wavs)\n",
        "        loss = criterion(outputs, labs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "#     if epoch % 10 == 0:\n",
        "    f1 = eval_model(model, val_loader)\n",
        "    f1_train = eval_model(model, train_loader)\n",
        "    print(f'epoch: {epoch}, f1_test: {f1}, f1_train: {f1_train}')\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        torch.save(model.state_dict(), '../baseline_fulldiv.pt')\n",
        "        \n",
        "    lr = lr * 0.95\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpKh3iO4G8Dj",
        "outputId": "229f0e88-a374-4568-9d19-88893b6e23f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, f1_test: 0.10881514510486336, f1_train: 0.12491591320488005\n",
            "epoch: 1, f1_test: 0.10223543943360824, f1_train: 0.10405710509574878\n",
            "epoch: 2, f1_test: 0.18530804184525632, f1_train: 0.200145335580391\n",
            "epoch: 3, f1_test: 0.32015738137241656, f1_train: 0.3580449360377917\n",
            "epoch: 4, f1_test: 0.29811833633904533, f1_train: 0.3174551726724046\n",
            "epoch: 5, f1_test: 0.417784315678757, f1_train: 0.49850246298394824\n",
            "epoch: 6, f1_test: 0.3912374113499492, f1_train: 0.48354827077720325\n",
            "epoch: 7, f1_test: 0.4318873063705564, f1_train: 0.5225243513684436\n",
            "epoch: 8, f1_test: 0.4778676833176374, f1_train: 0.5660152969088971\n",
            "epoch: 9, f1_test: 0.5132491049069522, f1_train: 0.6381335256051263\n",
            "epoch: 10, f1_test: 0.5903166679035904, f1_train: 0.7063885724994422\n",
            "epoch: 11, f1_test: 0.4310460495499517, f1_train: 0.5648748974008755\n",
            "epoch: 12, f1_test: 0.5985294435126046, f1_train: 0.7444643120071793\n",
            "epoch: 13, f1_test: 0.5668015887107496, f1_train: 0.7170246361989844\n",
            "epoch: 14, f1_test: 0.5819109979285183, f1_train: 0.7065273012313223\n",
            "epoch: 15, f1_test: 0.4994460734715051, f1_train: 0.6261958281219354\n",
            "epoch: 16, f1_test: 0.5506637656775426, f1_train: 0.6970457813698423\n",
            "epoch: 17, f1_test: 0.5914926401158744, f1_train: 0.7550658760797221\n",
            "epoch: 18, f1_test: 0.5745305981939326, f1_train: 0.7218897688006178\n",
            "epoch: 19, f1_test: 0.49076818784014253, f1_train: 0.6990248421749119\n",
            "epoch: 20, f1_test: 0.5917608865816527, f1_train: 0.7711641521176071\n",
            "epoch: 21, f1_test: 0.5269513204137587, f1_train: 0.6984678417402725\n",
            "epoch: 22, f1_test: 0.6176372719817571, f1_train: 0.8037089779593329\n",
            "epoch: 23, f1_test: 0.5890531015314512, f1_train: 0.7601311683576318\n",
            "epoch: 24, f1_test: 0.6578098039339219, f1_train: 0.8408007162182312\n",
            "epoch: 25, f1_test: 0.5919359930788974, f1_train: 0.7707415775639443\n",
            "epoch: 26, f1_test: 0.6072159975243824, f1_train: 0.8090256425156552\n",
            "epoch: 27, f1_test: 0.5440777815334485, f1_train: 0.721276200059955\n",
            "epoch: 28, f1_test: 0.5904955946626776, f1_train: 0.7906498532910466\n",
            "epoch: 29, f1_test: 0.551100826783659, f1_train: 0.7421467666886834\n",
            "epoch: 30, f1_test: 0.598495585118928, f1_train: 0.8057768286934442\n",
            "epoch: 31, f1_test: 0.565385453183284, f1_train: 0.7524217844172774\n",
            "epoch: 32, f1_test: 0.5924546686780217, f1_train: 0.7873515361899831\n",
            "epoch: 33, f1_test: 0.5761625776418332, f1_train: 0.78171272717659\n",
            "epoch: 34, f1_test: 0.6010967184415246, f1_train: 0.7913794064594959\n",
            "epoch: 35, f1_test: 0.6225200582487745, f1_train: 0.8220211260627198\n",
            "epoch: 36, f1_test: 0.6154987665375885, f1_train: 0.8098513109542227\n",
            "epoch: 37, f1_test: 0.6276741872846396, f1_train: 0.8538810754228757\n",
            "epoch: 38, f1_test: 0.6563169444551876, f1_train: 0.8504602804844006\n",
            "epoch: 39, f1_test: 0.5825464741390523, f1_train: 0.7962533000399401\n",
            "epoch: 40, f1_test: 0.5703798281560263, f1_train: 0.7986095519903187\n",
            "epoch: 41, f1_test: 0.635918882834135, f1_train: 0.8362561505111911\n",
            "epoch: 42, f1_test: 0.6384036036512205, f1_train: 0.825081670145402\n",
            "epoch: 43, f1_test: 0.6515081174358534, f1_train: 0.8705926919186222\n",
            "epoch: 44, f1_test: 0.5995282308760519, f1_train: 0.8250651881903946\n",
            "epoch: 45, f1_test: 0.6428437478762464, f1_train: 0.8686943456937761\n",
            "epoch: 46, f1_test: 0.6718858758097863, f1_train: 0.890244864099991\n",
            "epoch: 47, f1_test: 0.6443458150753947, f1_train: 0.8528517216044492\n",
            "epoch: 48, f1_test: 0.578201608385437, f1_train: 0.8004961801183286\n",
            "epoch: 49, f1_test: 0.6111627738397023, f1_train: 0.8293596696266575\n",
            "epoch: 50, f1_test: 0.6170788825215587, f1_train: 0.8422701471142797\n",
            "epoch: 51, f1_test: 0.6576062879553217, f1_train: 0.8650115064396552\n",
            "epoch: 52, f1_test: 0.6418491275900415, f1_train: 0.849463498289555\n",
            "epoch: 53, f1_test: 0.649265205448372, f1_train: 0.8608928283700389\n",
            "epoch: 54, f1_test: 0.6366544156471369, f1_train: 0.8570231138646746\n",
            "epoch: 55, f1_test: 0.6244816135944429, f1_train: 0.845277264289744\n",
            "epoch: 56, f1_test: 0.6314946183997457, f1_train: 0.8593203790971892\n",
            "epoch: 57, f1_test: 0.6438211357956312, f1_train: 0.8602254496799467\n",
            "epoch: 58, f1_test: 0.643007502103694, f1_train: 0.8657035253351103\n",
            "epoch: 59, f1_test: 0.6186413224207745, f1_train: 0.838914750775889\n",
            "epoch: 60, f1_test: 0.6154470416754582, f1_train: 0.8474125120264533\n",
            "epoch: 61, f1_test: 0.6257958229507115, f1_train: 0.8453900127079897\n",
            "epoch: 62, f1_test: 0.6495011178734529, f1_train: 0.8775969061360129\n",
            "epoch: 63, f1_test: 0.6599674283678085, f1_train: 0.8761578446647175\n",
            "epoch: 64, f1_test: 0.6330069827681721, f1_train: 0.8564219851493987\n",
            "epoch: 65, f1_test: 0.6564045051078145, f1_train: 0.876651421549882\n",
            "epoch: 66, f1_test: 0.6367725154816071, f1_train: 0.8706433368233719\n",
            "epoch: 67, f1_test: 0.63458421658479, f1_train: 0.8567394445135137\n",
            "epoch: 68, f1_test: 0.6513438612115117, f1_train: 0.870999902980224\n",
            "epoch: 69, f1_test: 0.6623625056445603, f1_train: 0.8760948799919952\n",
            "epoch: 70, f1_test: 0.6609544991939452, f1_train: 0.8731410078999148\n",
            "epoch: 71, f1_test: 0.6378347419615008, f1_train: 0.8496930212698016\n",
            "epoch: 72, f1_test: 0.6394379384271721, f1_train: 0.8706821404844569\n",
            "epoch: 73, f1_test: 0.6166052577522962, f1_train: 0.8446856445046587\n",
            "epoch: 74, f1_test: 0.6345060371651408, f1_train: 0.8491991268372158\n",
            "epoch: 75, f1_test: 0.6074901699311689, f1_train: 0.8301965948094073\n",
            "epoch: 76, f1_test: 0.610966538576716, f1_train: 0.844154840791633\n",
            "epoch: 77, f1_test: 0.5985820560229212, f1_train: 0.8376358592782873\n",
            "epoch: 78, f1_test: 0.6194821096118656, f1_train: 0.8487366687028438\n",
            "epoch: 79, f1_test: 0.6560573461127726, f1_train: 0.8726256773863139\n",
            "epoch: 80, f1_test: 0.6344895248107392, f1_train: 0.856415764916748\n",
            "epoch: 81, f1_test: 0.6487552910954827, f1_train: 0.8598412355222016\n",
            "epoch: 82, f1_test: 0.6525148284766339, f1_train: 0.8665307638547323\n",
            "epoch: 83, f1_test: 0.6179161501347941, f1_train: 0.856375787823583\n",
            "epoch: 84, f1_test: 0.6702695265849858, f1_train: 0.8763711140598177\n",
            "epoch: 85, f1_test: 0.6191187636550993, f1_train: 0.8589615998990325\n",
            "epoch: 86, f1_test: 0.6381557555019922, f1_train: 0.8636025362416176\n",
            "epoch: 87, f1_test: 0.6354837258922438, f1_train: 0.847304177531453\n",
            "epoch: 88, f1_test: 0.6267810998167131, f1_train: 0.8432948088939783\n",
            "epoch: 89, f1_test: 0.6414177237126276, f1_train: 0.8499759116512937\n",
            "epoch: 90, f1_test: 0.6130240323090885, f1_train: 0.8521482674116343\n",
            "epoch: 91, f1_test: 0.6400310540157973, f1_train: 0.852908112440478\n",
            "epoch: 92, f1_test: 0.6291353058166578, f1_train: 0.8620815670463886\n",
            "epoch: 93, f1_test: 0.6361705172172174, f1_train: 0.8584866580958663\n",
            "epoch: 94, f1_test: 0.6100015340183934, f1_train: 0.8477342387238043\n",
            "epoch: 95, f1_test: 0.6334028455658451, f1_train: 0.8625536096952566\n",
            "epoch: 96, f1_test: 0.6099898848990747, f1_train: 0.8463814292958673\n",
            "epoch: 97, f1_test: 0.6204840957233853, f1_train: 0.8453644466446095\n",
            "epoch: 98, f1_test: 0.6064934371167476, f1_train: 0.8401521920312207\n",
            "epoch: 99, f1_test: 0.6206432645738215, f1_train: 0.8515107546033077\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qKy7G76SRox"
      },
      "outputs": [],
      "source": [
        "# change of baseline model\n",
        "class ModelV2(nn.Module):\n",
        "    \n",
        "    def __init__(self, sample_rate=16000, n_classes=41):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=2)\n",
        "        self.cnn2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.cnn2extra = nn.Conv2d(in_channels=64, out_channels=20, kernel_size=1, padding=0)\n",
        "        \n",
        "        self.cnn3 = nn.Conv2d(in_channels=20, out_channels=3, kernel_size=3, padding=1)\n",
        "        \n",
        "        self.max_pool = nn.MaxPool2d(3, 2)\n",
        "       \n",
        "        self.features = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "            \n",
        "        self.lin1 = nn.Linear(1000, 333)\n",
        "        \n",
        "        self.lin2 = nn.Linear(333, 111)\n",
        "                \n",
        "        self.lin3 = nn.Linear(111, n_classes)\n",
        "\n",
        "        self.drop_layer = nn.Dropout(p=0.4) \n",
        "\n",
        "        self.cnn1_bn = nn.BatchNorm2d(32)\n",
        "        self.cnn2_bn = nn.BatchNorm2d(64)\n",
        "        self.cnn3_bn = nn.BatchNorm2d(3)\n",
        "        self.lin1_bn = nn.BatchNorm1d(333)\n",
        "        self.lin2_bn = nn.BatchNorm1d(111)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.ms(x)\n",
        "                \n",
        "        x = F.relu(self.cnn1_bn(self.cnn1(x)))\n",
        "        x = F.relu(self.cnn2_bn(self.cnn2(x)))\n",
        "        x = self.max_pool(x)\n",
        "        x = F.relu(self.cnn2extra(x))\n",
        "        x = F.relu(self.cnn3_bn(self.cnn3(x)))\n",
        "\n",
        "        x = self.features(x)\n",
        "\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.drop_layer(x)\n",
        "        x = F.relu(self.lin1_bn(self.lin1(x)))\n",
        "        x = F.relu(self.lin2_bn(self.lin2(x)))\n",
        "        x = self.lin3(x)\n",
        "        return x\n",
        "    \n",
        "    def inference(self, x):\n",
        "        x = self.forward(x)\n",
        "        x = F.softmax(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion2 = nn.CrossEntropyLoss()\n",
        "model2 = ModelV2()\n",
        "model2 = model2.cuda()\n",
        "lr = 1e-3\n",
        "\n",
        "optimizer2 = torch.optim.Adam(model2.parameters(), lr=lr)\n"
      ],
      "metadata": {
        "id": "OGiC6ntpiXvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epoch = 100\n",
        "best_f1 = 0\n",
        "for epoch in range(n_epoch):\n",
        "    model2.train()\n",
        "    for wavs, labs in train_loader:\n",
        "        optimizer2.zero_grad()\n",
        "        wavs, labs = wavs.cuda(), labs.cuda()\n",
        "        outputs = model2(wavs)\n",
        "        loss = criterion2(outputs, labs)\n",
        "        loss.backward()\n",
        "        optimizer2.step()\n",
        "\n",
        "        # scheduler.step()\n",
        "#     if epoch % 10 == 0:\n",
        "    f1 = eval_model(model2, val_loader)\n",
        "    f1_train = eval_model(model2, train_loader)\n",
        "    print(f'epoch: {epoch}, f1_test: {f1}, f1_train: {f1_train}')\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        torch.save(model2.state_dict(), '../baseline_fulldiv.pt')\n",
        "        \n",
        "    lr = lr * 0.97\n",
        "    for param_group in optimizer2.param_groups:\n",
        "        param_group['lr'] = lr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH2vh3PGDa3Q",
        "outputId": "30726a54-5b8a-4b48-bbf0-0a07e0f170f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 0, f1_test: 0.07697615112313103, f1_train: 0.07826489608877954\n",
            "epoch: 1, f1_test: 0.11683850869904917, f1_train: 0.11628960729452452\n",
            "epoch: 2, f1_test: 0.2154387726609989, f1_train: 0.2274105794427145\n",
            "epoch: 3, f1_test: 0.20669931918895773, f1_train: 0.24261859882051948\n",
            "epoch: 4, f1_test: 0.22127056803982595, f1_train: 0.2350701833177046\n",
            "epoch: 5, f1_test: 0.4143568490412995, f1_train: 0.4447747595370425\n",
            "epoch: 6, f1_test: 0.279094088237962, f1_train: 0.3443336355847003\n",
            "epoch: 7, f1_test: 0.3047462403599801, f1_train: 0.36571036476539914\n",
            "epoch: 8, f1_test: 0.34372829126542, f1_train: 0.3946142402827801\n",
            "epoch: 9, f1_test: 0.3901702044236138, f1_train: 0.43503587091207346\n",
            "epoch: 10, f1_test: 0.4939430832610174, f1_train: 0.5389643448163665\n",
            "epoch: 11, f1_test: 0.5177220053928165, f1_train: 0.6379532236724383\n",
            "epoch: 12, f1_test: 0.3442908222030643, f1_train: 0.42088265782089196\n",
            "epoch: 13, f1_test: 0.47609287753298274, f1_train: 0.5771338710963421\n",
            "epoch: 14, f1_test: 0.44648226849692346, f1_train: 0.5667264352017923\n",
            "epoch: 15, f1_test: 0.416907149193633, f1_train: 0.5091648047785068\n",
            "epoch: 16, f1_test: 0.5698797639157515, f1_train: 0.7109470060706555\n",
            "epoch: 17, f1_test: 0.5328759102952344, f1_train: 0.6659313192980986\n",
            "epoch: 18, f1_test: 0.5717121639179277, f1_train: 0.6982064859699031\n",
            "epoch: 19, f1_test: 0.5619917533207219, f1_train: 0.727954371628665\n",
            "epoch: 20, f1_test: 0.5103232328830365, f1_train: 0.6598768627627467\n",
            "epoch: 21, f1_test: 0.5813154225851046, f1_train: 0.7491905746131201\n",
            "epoch: 22, f1_test: 0.5332885044077886, f1_train: 0.717807782273307\n",
            "epoch: 23, f1_test: 0.5642633985979655, f1_train: 0.7162463219531586\n",
            "epoch: 24, f1_test: 0.4577963159125679, f1_train: 0.6245951210274574\n",
            "epoch: 25, f1_test: 0.5823012799055938, f1_train: 0.7736978331942266\n",
            "epoch: 26, f1_test: 0.5947861216208689, f1_train: 0.7949314506406825\n",
            "epoch: 27, f1_test: 0.49226157472496695, f1_train: 0.6390097528108079\n",
            "epoch: 28, f1_test: 0.594636029976472, f1_train: 0.7907523065007579\n",
            "epoch: 29, f1_test: 0.6094676411235371, f1_train: 0.7953308962089287\n",
            "epoch: 30, f1_test: 0.3220745317275698, f1_train: 0.42365021773946854\n",
            "epoch: 31, f1_test: 0.6146987497533336, f1_train: 0.8029748903933904\n",
            "epoch: 32, f1_test: 0.610925369285587, f1_train: 0.8164423327782193\n",
            "epoch: 33, f1_test: 0.6024399009439885, f1_train: 0.8163849276900133\n",
            "epoch: 34, f1_test: 0.6094056055972987, f1_train: 0.8257508318700746\n",
            "epoch: 35, f1_test: 0.6245327537848557, f1_train: 0.8312671542809007\n",
            "epoch: 36, f1_test: 0.5856812157150427, f1_train: 0.8031715418536866\n",
            "epoch: 37, f1_test: 0.5729184906023108, f1_train: 0.7889496806183909\n",
            "epoch: 38, f1_test: 0.6312921149908133, f1_train: 0.8495498420004273\n",
            "epoch: 39, f1_test: 0.5739996431319013, f1_train: 0.7435335538882775\n",
            "epoch: 40, f1_test: 0.5998282319734197, f1_train: 0.8150089478029456\n",
            "epoch: 41, f1_test: 0.5946729795848764, f1_train: 0.8188438250390474\n",
            "epoch: 42, f1_test: 0.6013453441535048, f1_train: 0.8191857262355162\n",
            "epoch: 43, f1_test: 0.59729524322156, f1_train: 0.8022080769576315\n",
            "epoch: 44, f1_test: 0.6280357474472635, f1_train: 0.8588530602336168\n",
            "epoch: 45, f1_test: 0.599662946586246, f1_train: 0.8165420607997368\n",
            "epoch: 46, f1_test: 0.590625193926136, f1_train: 0.8094438690544726\n",
            "epoch: 47, f1_test: 0.6268560965871683, f1_train: 0.8443211104379136\n",
            "epoch: 48, f1_test: 0.6320795729453771, f1_train: 0.8541608351380786\n",
            "epoch: 49, f1_test: 0.637305615884, f1_train: 0.8500032204049951\n",
            "epoch: 50, f1_test: 0.6130569771659057, f1_train: 0.845988893882713\n",
            "epoch: 51, f1_test: 0.602439102542009, f1_train: 0.8318981956346224\n",
            "epoch: 52, f1_test: 0.5804327256155656, f1_train: 0.8180162944039886\n",
            "epoch: 53, f1_test: 0.6051221183869756, f1_train: 0.8428492699273198\n",
            "epoch: 54, f1_test: 0.5826776662062688, f1_train: 0.8276851017101524\n",
            "epoch: 55, f1_test: 0.6116736524518712, f1_train: 0.8500876335553097\n",
            "epoch: 56, f1_test: 0.6213496369338279, f1_train: 0.8564558131097365\n",
            "epoch: 57, f1_test: 0.6053856920917181, f1_train: 0.8100465971947836\n",
            "epoch: 58, f1_test: 0.6053168734866546, f1_train: 0.8456957606971185\n",
            "epoch: 59, f1_test: 0.6121948930945881, f1_train: 0.8401519207665393\n",
            "epoch: 60, f1_test: 0.6204069465101588, f1_train: 0.8384581425611981\n",
            "epoch: 61, f1_test: 0.6207513153337962, f1_train: 0.8411471978471471\n",
            "epoch: 62, f1_test: 0.616045536118656, f1_train: 0.8331242275680893\n",
            "epoch: 63, f1_test: 0.6046957507183107, f1_train: 0.8380878694174944\n",
            "epoch: 64, f1_test: 0.6085208859719916, f1_train: 0.8473940981094356\n",
            "epoch: 65, f1_test: 0.6317160445069367, f1_train: 0.8634516093771692\n",
            "epoch: 66, f1_test: 0.6160845634522184, f1_train: 0.8510472326996533\n",
            "epoch: 67, f1_test: 0.5997436712344697, f1_train: 0.8422098864337633\n",
            "epoch: 68, f1_test: 0.6112447272709248, f1_train: 0.8449795399215182\n",
            "epoch: 69, f1_test: 0.6178822158099515, f1_train: 0.8640141047751797\n",
            "epoch: 70, f1_test: 0.6211620693040663, f1_train: 0.8524646239194584\n",
            "epoch: 71, f1_test: 0.6363321177342388, f1_train: 0.853443533028056\n",
            "epoch: 72, f1_test: 0.6324043189490901, f1_train: 0.8543905023532871\n",
            "epoch: 73, f1_test: 0.6428310076778284, f1_train: 0.835380299630264\n",
            "epoch: 74, f1_test: 0.6614105676139654, f1_train: 0.8576284878539658\n",
            "epoch: 75, f1_test: 0.6666376154208573, f1_train: 0.8503645152592648\n",
            "epoch: 76, f1_test: 0.6703501494646633, f1_train: 0.8659740374738829\n",
            "epoch: 77, f1_test: 0.687914216096621, f1_train: 0.8673532866386101\n",
            "epoch: 78, f1_test: 0.6842093256930114, f1_train: 0.8668187499686563\n",
            "epoch: 79, f1_test: 0.6915417482032242, f1_train: 0.8610929157790083\n",
            "epoch: 80, f1_test: 0.6980902373264148, f1_train: 0.8800370594821453\n",
            "epoch: 81, f1_test: 0.718103250240271, f1_train: 0.8719083599151642\n",
            "epoch: 82, f1_test: 0.7329876705927667, f1_train: 0.884946070704862\n",
            "epoch: 83, f1_test: 0.7150798158951556, f1_train: 0.8707325561529364\n",
            "epoch: 84, f1_test: 0.7201225582087057, f1_train: 0.8621941811674182\n",
            "epoch: 85, f1_test: 0.7204191602691191, f1_train: 0.8660175444408935\n",
            "epoch: 86, f1_test: 0.741153705851734, f1_train: 0.8816220668255277\n",
            "epoch: 87, f1_test: 0.7292129888370092, f1_train: 0.8735133586997481\n",
            "epoch: 88, f1_test: 0.7334832628615389, f1_train: 0.8799797922462089\n",
            "epoch: 89, f1_test: 0.7288473564925832, f1_train: 0.8663523093820432\n",
            "epoch: 90, f1_test: 0.7342224925327561, f1_train: 0.8787901455441752\n",
            "epoch: 91, f1_test: 0.728236406006596, f1_train: 0.8847532835839697\n",
            "epoch: 92, f1_test: 0.7262928480484123, f1_train: 0.8921130224053326\n",
            "epoch: 93, f1_test: 0.7320941287772246, f1_train: 0.8814729108966873\n",
            "epoch: 94, f1_test: 0.7330500437412783, f1_train: 0.8799945119048495\n",
            "epoch: 95, f1_test: 0.7270945430065813, f1_train: 0.8779700522564199\n",
            "epoch: 96, f1_test: 0.7419114926653602, f1_train: 0.8811647397250476\n",
            "epoch: 97, f1_test: 0.7427890652841716, f1_train: 0.8796646462092503\n",
            "epoch: 98, f1_test: 0.7158644239032377, f1_train: 0.9144266628686372\n",
            "epoch: 99, f1_test: 0.7502365086404009, f1_train: 0.8920592465703642\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make a model\n",
        "model_name = 'model2_fulldiv.pt'\n",
        "model = ModelV2().cuda()\n",
        "model.load_state_dict(torch.load(os.path.join('..', model_name)))\n",
        "model.eval()\n",
        "forecast = []\n",
        "with torch.no_grad():\n",
        "    for wavs in tqdm(test_loader):\n",
        "        wavs = wavs.cuda()\n",
        "        outputs = model.inference(wavs)\n",
        "        outputs = outputs.detach().cpu().numpy().argmax(axis=1)\n",
        "        forecast.append(outputs)\n",
        "forecast = [x for sublist in forecast for x in sublist]\n",
        "decoder = {classes_dict[cl]:cl for cl in classes_dict}\n",
        "forecast = pd.Series(forecast).map(decoder)\n",
        "df_test['label'] = forecast\n",
        "df_test.to_csv(f'{model_name}.csv', index=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9Op53Os6p6A",
        "outputId": "bad151f6-088b-4752-c4bd-5ae54ed2d99d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/93 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "100%|| 93/93 [00:29<00:00,  3.18it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BjfSSZ0Y5WkX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}